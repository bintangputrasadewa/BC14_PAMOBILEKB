# -*- coding: utf-8 -*-
"""PA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_6anPALA8CgunR_dZ4NJszlyTxaUZ2I
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

df = pd.read_csv('food.csv')
df.head()

"""# 1. Memilih kolom yang dibutuhkan
---
"""

selected_columns = ['Category', 'Description', 'Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']
filtered_data = df[selected_columns]

# Menampilkan jumlah nilai kosong sebelum diisi
print("Nilai kosong sebelum diisi:")
print(filtered_data.isnull().sum())

# Menampilkan data dengan nilai kosong
print("\nData dengan nilai kosong:")
print(filtered_data[filtered_data.isnull().any(axis=1)])

"""# 2. Menangani nilai kosong (mengisi dengan rata-rata)
---
"""

# Menggunakan .loc untuk mengisi nilai NaN dengan rata-rata pada kolom Data.Protein
filtered_data.loc[:, 'Data.Protein'] = filtered_data['Data.Protein'].fillna(filtered_data['Data.Protein'].mean())
filtered_data.loc[:, 'Data.Fat.Total Lipid'] = filtered_data['Data.Fat.Total Lipid'].fillna(filtered_data['Data.Fat.Total Lipid'].mean())
filtered_data.loc[:, 'Data.Kilocalories'] = filtered_data['Data.Kilocalories'].fillna(filtered_data['Data.Kilocalories'].mean())
filtered_data.loc[:, 'Data.Carbohydrate'] = filtered_data['Data.Carbohydrate'].fillna(filtered_data['Data.Carbohydrate'].mean())

# Menampilkan jumlah nilai kosong setelah diisi
print("\nNilai kosong setelah diisi:")
print(filtered_data.isnull().sum())

# Menampilkan data dengan nilai kosong setelah diisi (seharusnya tidak ada)
print("\nData dengan nilai kosong setelah diisi:")
print(filtered_data[filtered_data.isnull().any(axis=1)])

"""# 3. Menghapus data duplikat
---
"""

# Melihat jumlah duplicate value
duplicate = df.duplicated().sum()
print('Jumlah nilai duplikat pada data: ', duplicate)

"""##### Tidak ada data duplikat, jadi kita tidak menghapus

## Handling Outlier
"""

from scipy import stats

# sebelum handling outlier
fig, axes = plt.subplots(1, 2, figsize=(10, 6))
plt.tight_layout()
sns.boxplot(df['Data.Kilocalories'], orient='v', ax=axes[0], color='skyblue')
axes[0].title.set_text("Sebelum")

# Menangani outlier dengan IQR
Q1 = df['Data.Kilocalories'].quantile(0.25)  # Kuartil pertama
Q3 = df['Data.Kilocalories'].quantile(0.75)  # Kuartil ketiga
IQR = Q3 - Q1  # Interquartile Range

# Ambil data di antara Q1 - 1.5*IQR dan Q3 + 1.5*IQR
df = df[(df['Data.Kilocalories'] >= (Q1 - 1.5 * IQR)) &
        (df['Data.Kilocalories'] <= (Q3 + 1.5 * IQR))]

# setelah handling outlier
sns.boxplot(df['Data.Kilocalories'], orient='v', ax=axes[1], color='green')
axes[1].title.set_text("Sesudah")

plt.show()

"""#4. Future Eng
---
"""

# Mengubah kolom menjadi float sebelum transformasi
filtered_data.loc[:, ['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories']] = filtered_data[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories']].astype(float)

# Terapkan MinMaxScaler
scaler = MinMaxScaler()
filtered_data.loc[:, ['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories']] = scaler.fit_transform(filtered_data[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories']])

# Menambahkan kolom Low_Calories dan High_Calories berdasarkan Data.Kilocalories yang sudah dinormalisasi
# Menetapkan ambang batas berdasarkan Data.Kilocalories yang sudah dinormalisasi
low_threshold = filtered_data['Data.Kilocalories'].quantile(0.25)  # Ambang batas Q1 (25%)
high_threshold = filtered_data['Data.Kilocalories'].quantile(0.75)  # Ambang batas Q3 (75%)

# Menambahkan kolom Calorie_Label untuk menentukan Low dan High berdasarkan Data.Kilocalories
filtered_data['Calorie_Label'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'Low' if x <= low_threshold else 'High'  # Menetapkan dua kategori: Low dan High
)

# Menambahkan kolom Low_Calories dan High_Calories dengan nilai "Low" dan "High"
filtered_data['Low_Calories'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'Low' if x <= low_threshold else ''  # "Low" jika kalori <= ambang batas rendah, jika tidak kosong
)

filtered_data['High_Calories'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'High' if x > high_threshold else ''  # "High" jika kalori > ambang batas tinggi, jika tidak kosong
)

# Menampilkan distribusi label dan data yang sudah dimodifikasi
print("Distribusi label:")
print(filtered_data['Calorie_Label'].value_counts())

# Menampilkan data dengan kolom tambahan Low_Calories dan High_Calories
print(filtered_data[['Description', 'Data.Kilocalories', 'Low_Calories', 'High_Calories']].head())

# Menampilkan data yang memiliki nilai "Low" pada kolom Low_Calories
low_calories_data = filtered_data[filtered_data['Low_Calories'] == 'Low']

# Menampilkan hasilnya
print("Data dengan Low Calories:")
print(low_calories_data[['Description', 'Data.Kilocalories', 'Low_Calories']].head())

"""# 5. Normalisasi kolom numerik (Protein, Fat, Kalori) menggunakan MinMaxScaler
---
"""

# Mengubah kolom menjadi float sebelum transformasi
filtered_data.loc[:, ['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']] = filtered_data[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']].astype(float)

# Terapkan MinMaxScaler
scaler = MinMaxScaler()
filtered_data.loc[:, ['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']] = scaler.fit_transform(filtered_data[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']])

# Menambahkan kolom Low_Calories dan High_Calories berdasarkan Data.Kilocalories yang sudah dinormalisasi
# Menetapkan ambang batas berdasarkan Data.Kilocalories yang sudah dinormalisasi
low_threshold = filtered_data['Data.Kilocalories'].quantile(0.25)  # Ambang batas Q1 (25%)
high_threshold = filtered_data['Data.Kilocalories'].quantile(0.75)  # Ambang batas Q3 (75%)

# Menambahkan kolom Calorie_Label untuk menentukan Low dan High berdasarkan Data.Kilocalories
filtered_data['Calorie_Label'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'Low' if x <= low_threshold else 'High'  # Menetapkan dua kategori: Low dan High
)

# Menambahkan kolom Low_Calories dan High_Calories dengan nilai "Low" dan "High"
filtered_data['Low_Calories'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'Low' if x <= low_threshold else ''  # "Low" jika kalori <= ambang batas rendah, jika tidak kosong
)

filtered_data['High_Calories'] = filtered_data['Data.Kilocalories'].apply(
    lambda x: 'High' if x > high_threshold else ''  # "High" jika kalori > ambang batas tinggi, jika tidak kosong
)

# Menampilkan distribusi label dan data yang sudah dimodifikasi
print("Distribusi label:")
print(filtered_data['Calorie_Label'].value_counts())

# Menampilkan data dengan kolom tambahan Low_Calories dan High_Calories
print(filtered_data[['Description', 'Data.Kilocalories', 'Low_Calories', 'High_Calories']].head())

"""# Menampilkan dataset yang telah diproses
---
"""

output_path = 'preprocessed_data.csv'
filtered_data.to_csv(output_path, index=False)

print(filtered_data.head())

"""# Supervised Learning
---

## Kilocalories sebagai target
"""

df = pd.read_csv('preprocessed_data.csv')

# Mengambil fitur dan target
X = df[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Carbohydrate']]  # Fitur
y = df['Data.Kilocalories']  # Target

# Normalisasi data fitur menggunakan MinMaxScaler
scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)  # Normalisasi X

# Membagi data ke dalam train set dan test set
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)

# Membuat model SVR dengan kernel linear
svm = SVR(kernel="linear")
svm.fit(X_train, y_train)  # Latih model dengan data training

# Prediksi data test
y_pred = svm.predict(X_test)

# Evaluasi model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Menampilkan hasil evaluasi
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("R-Squared:", r2)

# Visualisasi hasil prediksi vs nilai aktual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, color="blue")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color="red")
plt.title("Hasil Prediksi vs Nilai Aktual")
plt.xlabel("Nilai Aktual")
plt.ylabel("Prediksi")
plt.show()

"""## Metode Evaluasi dalam Klasifikasi"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
X = df[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Carbohydrate']]  # Fitur
y = df['Data.Kilocalories']  # Target

# Normalisasi data fitur menggunakan MinMaxScaler
scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)  # Normalisasi X

# Membagi data ke dalam train set dan test set
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)

# Buat objek regressor SVM dengan kernel linear
svm = SVR(kernel="linear")  # Gunakan SVR untuk regresi
svm.fit(X_train, y_train)  # Latih regressor dengan data train

# Prediksi data test
y_pred = svm.predict(X_test)

# Evaluasi hasil prediksi menggunakan metrik regresi
print("MAE :", mean_absolute_error(y_test, y_pred))
print("MSE :", mean_squared_error(y_test, y_pred))
print("RMSE :", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R-Squared :", r2_score(y_test, y_pred))

df.info()

"""Train SVR"""

from sklearn.model_selection import GridSearchCV
# Generate some data (you can replace this with your actual dataset)
np.random.seed(42)
X = np.random.rand(100, 1) * 10  # Feature (e.g., 'Protein' or 'Fat')
y = 3 * X.squeeze() + np.random.randn(100) * 2  # Target (e.g., 'Calories')

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create the SVR model
svr = SVR(kernel='linear')  # You can change the kernel to 'linear', 'poly', etc.

# Fit the model to the training data
svr.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svr.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-Squared: {r2}")

# Hyperparameter Tuning using GridSearchCV
# Define the hyperparameters grid
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto'],
    'degree': [2, 3, 4],  # Degree is relevant only for the 'poly' kernel
}

# Set up GridSearchCV
grid_search = GridSearchCV(svr, param_grid, cv=5, verbose=2, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Print the best hyperparameters found
print("Best hyperparameters found: ", grid_search.best_params_)

# Evaluate the best model on the test set
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)

# Evaluate the tuned model
mae_best = mean_absolute_error(y_test, y_pred_best)
mse_best = mean_squared_error(y_test, y_pred_best)
rmse_best = np.sqrt(mse_best)
r2_best = r2_score(y_test, y_pred_best)

print(f"Best Model - MAE: {mae_best}")
print(f"Best Model - MSE: {mse_best}")
print(f"Best Model - RMSE: {rmse_best}")
print(f"Best Model - R-Squared: {r2_best}")

# Plotting the results
plt.scatter(X_test, y_test, color='blue', label='Actual')
plt.scatter(X_test, y_pred_best, color='red', label='Predicted')
plt.title('SVR - Actual vs Predicted')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.legend()
plt.show()

from sklearn.model_selection import RandomizedSearchCV
from sklearn.svm import SVR
from sklearn.metrics import r2_score

# Parameter grid (lebih kecil untuk eksperimen cepat)
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto'],
    'degree': [2, 3, 4]
}

# Randomized Search for Hyperparameters
random_search = RandomizedSearchCV(SVR(), param_distributions=param_grid, n_iter=10, cv=5, verbose=2, n_jobs=-1)
random_search.fit(X_train, y_train)

# Evaluasi dengan model terbaik
best_model = random_search.best_estimator_
y_pred_best = best_model.predict(X_test)
print("Best Model - R-Squared: ", r2_score(y_test, y_pred_best))

# Number of rows in the dataset
print("Number of rows (data points):", len(df))

# Prediksi data test
y_pred = svm.predict(X_test)

# Evaluasi model menggunakan MAE, MSE, RMSE, dan R2
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Menampilkan hasil evaluasi
print("Mean Absolute Error (MAE):", mae)
print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
print("R-Squared:", r2)

# Visualisasi hasil prediksi vs nilai aktual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7, color="blue")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2, color="red")
plt.title("Hasil Prediksi vs Nilai Aktual")
plt.xlabel("Nilai Aktual")
plt.ylabel("Prediksi")
plt.show()

# Visualisasi residual (selisih antara nilai aktual dan prediksi)
residuals = y_test - y_pred

plt.figure(figsize=(8, 6))
plt.scatter(y_pred, residuals, alpha=0.7, color="green")
plt.hlines(y=0, xmin=y_pred.min(), xmax=y_pred.max(), colors='red', linestyles='--')
plt.title("Residual Plot")
plt.xlabel("Prediksi")
plt.ylabel("Residuals (Actual - Predicted)")
plt.show()

# Histogram dari nilai prediksi
plt.figure(figsize=(8, 6))
plt.hist(y_pred, bins=20, color='purple', alpha=0.7)
plt.title("Distribusi Prediksi")
plt.xlabel("Prediksi")
plt.ylabel("Frekuensi")
plt.show()

# prompt: buatkan saya tampilan korelasinya

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the preprocessed data
df = pd.read_csv('preprocessed_data.csv')

# Calculate the correlation matrix
correlation_matrix = df[['Data.Protein', 'Data.Fat.Total Lipid', 'Data.Kilocalories', 'Data.Carbohydrate']].corr()

# Create a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Features')
plt.show()